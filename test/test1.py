# -*- coding:utf-8 -*-

from configparser import ConfigParser
from time import sleep

import librosa

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from PIL import Image
import pathlib
import csv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import keras
from keras import layers
from keras import layers
import keras
from keras.models import Sequential
import warnings

warnings.filterwarnings('ignore')


def read_all_file(record_files):
    if os.path.isdir(record_files):
        files = os.listdir(record_files)
        for file in files:
            record_path = record_files + "/" + file
            if os.path.isdir(record_path):
                read_all_file(record_path)
            else:
                # print(record_path)
                list = file.split('.')
                if list[len(list) - 1] == "pk":
                    continue
                else:
                    feature_extract(record_path)
    else:
        # print(record_files)
        feature_extract(record_files)


def feature_extract(audio):
    genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()
    # for g in genres:
    if True:
        # for filename in os.listdir(f'./drive/My Drive/genres/{g}'):
        songname = audio
        strs = songname.split('/')
        song = strs.pop(len(strs) - 1)
        y, sr = librosa.load(songname, mono=True, duration=30)
        rmse = librosa.feature.rms(y=y)
        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)
        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)
        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)
        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
        zcr = librosa.feature.zero_crossing_rate(y)
        mfcc = librosa.feature.mfcc(y=y, sr=sr)
        to_append = f'{song} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'
        for e in mfcc:
            to_append += f' {np.mean(e)}'
        csv_file = open('dataset.csv', 'a', newline='')
        with csv_file:
            writer = csv.writer(csv_file)
            writer.writerow(to_append.split())


# model = Sequential()
# model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))
# model.add(layers.Dense(128, activation='relu'))
# model.add(layers.Dense(64, activation='relu'))
# model.add(layers.Dense(10, activation='softmax'))
# model.compile(optimizer='adam',
#               loss='sparse_categorical_crossentropy',
#               metrics=['accuracy'])


if __name__ == "__main__":
    # # read property file
    # config = ConfigParser()
    # config.read('property.cfg')
    # # get the path of mp3 file
    # # mp3 = config.get("mp3files", "mp3file1")
    # mp3files = config.options("mp3files")
    # sleep(1)
    # print("file name       " + "均方根能量        " + "过零率         " + "谱质心          ", end="")
    # print("mfcc         " + "频谱平坦度          " + "频谱通量         " + "基音频率       ", end="")
    # print("响度          " + "尖锐度")
    #
    # header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'
    # for i in range(1, 21):
    #     header += f' mfcc{i}'
    # header += ' label'
    # header = header.split()
    #
    # csv_file = open('dataset.csv', 'w', newline='')
    # with csv_file:
    #     writer = csv.writer(csv_file)
    #     writer.writerow(header)
    #
    #
    # for i in mp3files:
    #     record_files = config.get("mp3files", i)
    #     read_all_file(record_files)

    data = pd.read_csv('dataset.csv')
    data.head()  # Dropping unneccesary columns
    data = data.drop(['filename'], axis=1)  # Encoding the Labels
    genre_list = data.iloc[:, -1]
    encoder = LabelEncoder()
    y = encoder.fit_transform(genre_list)  # Scaling the Feature columns
    scaler = StandardScaler()
    X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype=float))  # Dividing data into training and Testing set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    model = Sequential()
    model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(10, activation='softmax'))
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    classifier = model.fit(X_train, y_train, epochs=100, batch_size=128)
